# -*- coding: utf-8 -*-
"""60009220112_SAUMYA DESAI_ML_TASK3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GO51eQaejbuFSBfdwba7hEtZwgpceXa4
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

df = pd.read_csv('web-page-phishing.csv')
df

# prompt: Drop the NaN values from all the columns

df.dropna(inplace=True)

df.info()

df.describe()

plt.figure(figsize=(16, 10))
sns.heatmap(df.corr(), annot = True)
plt.show()

df = df.drop('n_equal', axis = 1)

plt.figure(figsize=(16, 10))
sns.heatmap(df.corr(), annot = True)
plt.show()

# prompt: train logistic, decision, random forest and give accuracy, precision and recall for each

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score

X = df.drop('phishing', axis=1)
y = df['phishing']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Logistic Regression
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred_logreg = logreg.predict(X_test)
print('Logistic Regression:')
print('- Accuracy:', accuracy_score(y_test, y_pred_logreg))
print('- Precision:', precision_score(y_test, y_pred_logreg))
print('- Recall:', recall_score(y_test, y_pred_logreg))

# Decision Tree
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, y_train)
y_pred_decision_tree = decision_tree.predict(X_test)
print('Decision Tree:')
print('- Accuracy:', accuracy_score(y_test, y_pred_decision_tree))
print('- Precision:', precision_score(y_test, y_pred_decision_tree))
print('- Recall:', recall_score(y_test, y_pred_decision_tree))

# Random Forest
random_forest = RandomForestClassifier()
random_forest.fit(X_train, y_train)
y_pred_random_forest = random_forest.predict(X_test)
print('Random Forest:')
print('- Accuracy:', accuracy_score(y_test, y_pred_random_forest))
print('- Precision:', precision_score(y_test, y_pred_random_forest))
print('- Recall:', recall_score(y_test, y_pred_random_forest))

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

X = df.iloc[:, :-1]
y = df.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

models = [LogisticRegression(max_iter=10000), DecisionTreeClassifier(), RandomForestClassifier(n_estimators=100), KNeighborsClassifier(n_neighbors=3)]

best_accuracy = 0
best_model = None

for model in models:
    print(f"Training model - {str(model)}")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"{model.__class__.__name__}: Accuracy = {accuracy:.2f}")
    report = classification_report(y_test, y_pred)
    print(report)

    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_model = model

print(f"\nBest Model: {best_model.__class__.__name__}, Accuracy = {best_accuracy:.2f}")

# prompt: build me classification report

from sklearn.metrics import classification_report

# Get predictions from the best model
y_pred = best_model.predict(X_test)

# Generate the classification report
report = classification_report(y_test, y_pred)
print(report)

model.predict(pd.DataFrame({'url_length': [41],
            'n_dots': [2],
            'n_hypens': [1],
            'n_underline': [0],
            'n_slash': [4],
            'n_questionmark': [0],
            'n_at': [0],
            'n_and': [0],
            'n_exclamation': [0],
            'n_space': [0],
            'n_tilde': [0],
            'n_comma': [0],
            'n_plus': [0],
            'n_asterisk': [0],
            'n_hastag': [0],
            'n_dollar': [0],
            'n_percent': [0],
            'n_redirection': [0]}))

phishing_count = df['phishing'].value_counts()
print(phishing_count)

# prompt: drop n_exclamation	n_space	n_tilde	n_comma	n_plus	n_asterisk	n_hastag	n_dollar	n_percent	n_redirection

df = df.drop(['n_exclamation', 'n_space', 'n_tilde', 'n_comma', 'n_plus', 'n_asterisk', 'n_hastag', 'n_dollar', 'n_percent', 'n_redirection'], axis=1)
df.head()

df

df.columns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score

X = df.drop('phishing', axis=1)
y = df['phishing']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Logistic Regression
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred_logreg = logreg.predict(X_test)
print('Logistic Regression:')
print('- Accuracy:', accuracy_score(y_test, y_pred_logreg))
print('- Precision:', precision_score(y_test, y_pred_logreg))
print('- Recall:', recall_score(y_test, y_pred_logreg))

# Decision Tree
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, y_train)
y_pred_decision_tree = decision_tree.predict(X_test)
print('Decision Tree:')
print('- Accuracy:', accuracy_score(y_test, y_pred_decision_tree))
print('- Precision:', precision_score(y_test, y_pred_decision_tree))
print('- Recall:', recall_score(y_test, y_pred_decision_tree))

# Random Forest
random_forest = RandomForestClassifier()
random_forest.fit(X_train, y_train)
y_pred_random_forest = random_forest.predict(X_test)
print('Random Forest:')
print('- Accuracy:', accuracy_score(y_test, y_pred_random_forest))
print('- Precision:', precision_score(y_test, y_pred_random_forest))
print('- Recall:', recall_score(y_test, y_pred_random_forest))

# prompt: adaboost with random forest

from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier

# Instantiate the Random Forest classifier
random_forest = RandomForestClassifier()

# Instantiate the AdaBoost classifier with the Random Forest classifier as the base estimator
adaboost = AdaBoostClassifier(estimator=random_forest)

# Fit the AdaBoost classifier on the training data
adaboost.fit(X_train, y_train)

# Predict the labels of the test data
y_pred_adaboost = adaboost.predict(X_test)

# Evaluate the accuracy of the AdaBoost classifier
accuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)
print(f"Accuracy of the AdaBoost classifier: {accuracy_adaboost:.2f}")

print('- Precision:', precision_score(y_test, y_pred_adaboost))
print('- Recall:', recall_score(y_test, y_pred_adaboost))

joblib.dump(adaboost, 'adaboost.pkl')

